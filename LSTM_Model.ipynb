{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38979f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7369a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, SpatialDropout1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the Disneyland reviews dataset\n",
    "reviews_df = pd.read_csv('DisneylandReviews.csv',encoding='ISO-8859-1')\n",
    "#\n",
    "# Remove irrelevant columns\n",
    "#reviews_df = reviews_df[['Review Text', 'Rating']]\n",
    "\n",
    "# Remove missing values\n",
    "reviews_df = reviews_df.dropna()\n",
    "\n",
    "# Remove punctuations and convert to lowercase\n",
    "def preprocess_text(text):\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "reviews_df['Review_Text'] = reviews_df['Review_Text'].apply(preprocess_text)\n",
    "\n",
    "# Tokenize the reviews\n",
    "reviews_df['Tokenized'] = reviews_df['Review_Text'].apply(word_tokenize)\n",
    "\n",
    "# Remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_stop_words(tokens):\n",
    "    return [word for word in tokens if not word in stop_words]\n",
    "\n",
    "reviews_df['Tokenized'] = reviews_df['Tokenized'].apply(remove_stop_words)\n",
    "\n",
    "# Convert ratings to sentiment labels\n",
    "def convert_rating_to_label(rating):\n",
    "    if rating >= 4:\n",
    "        return 'positive'\n",
    "    elif rating <= 2:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "reviews_df['Sentiment'] = reviews_df['Rating'].apply(convert_rating_to_label)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    reviews_df['Tokenized'], reviews_df['Sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Create word embeddings\n",
    "max_words = 10000\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad the sequences to a fixed length\n",
    "max_seq_length = 200\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_seq_length, padding='post', truncating='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_seq_length, padding='post', truncating='post')\n",
    "\n",
    "# Build the LSTM model\n",
    "embedding_size = 100\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_size, input_length=max_seq_length))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Convert sentiment labels to one-hot encoding\n",
    "y_train_enc = pd.get_dummies(y_train)\n",
    "y_test_enc = pd.get_dummies(y_test)\n",
    "\n",
    "# Train the model\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "model.fit(X_train_pad, y_train_enc, validation_data=(X_test_pad, y_test_enc), batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_pad, y_test_enc)\n",
    "print(f\"Loss: {loss}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06ead95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify new reviews\n",
    "def classify_review(review_text):\n",
    "    # Preprocess the review\n",
    "    review_text = preprocess_text(review_text)\n",
    "    tokens = word_tokenize(review_text)\n",
    "    tokens = remove_stop_words(tokens)\n",
    "    sequence = tokenizer.texts_to_sequences([tokens])[0]\n",
    "    padded = pad_sequences([sequence], maxlen=max_seq_length, padding='post', truncating='post')\n",
    "\n",
    "    # Predict the sentiment\n",
    "    sentiment_probs = model.predict(padded)[0]\n",
    "    sentiment_label = np.argmax(sentiment_probs)\n",
    "    if sentiment_label == 0:\n",
    "        return 'negative'\n",
    "    elif sentiment_label == 1:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180b4bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new review\n",
    "new_review = \"I had an amazing time at Disneyland! The rides were so much fun and the atmosphere was magical.\"\n",
    "\n",
    "# Preprocess the review\n",
    "new_review = preprocess_text(new_review)\n",
    "new_review_tokens = word_tokenize(new_review)\n",
    "new_review_tokens = remove_stop_words(new_review_tokens)\n",
    "new_review_seq = tokenizer.texts_to_sequences([new_review_tokens])\n",
    "new_review_pad = pad_sequences(new_review_seq, maxlen=max_seq_length, padding='post', truncating='post')\n",
    "\n",
    "# Make a prediction using the trained model\n",
    "prediction = model.predict(new_review_pad)\n",
    "\n",
    "# Get the predicted sentiment label\n",
    "sentiment_labels = ['negative', 'neutral', 'positive']\n",
    "predicted_label = sentiment_labels[np.argmax(prediction)]\n",
    "\n",
    "# Print the predicted label\n",
    "print(f\"Predicted sentiment label: {predicted_label}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
